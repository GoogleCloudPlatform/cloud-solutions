{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3aac354",
   "metadata": {},
   "source": [
    "# Dataset Experiments\n",
    "\n",
    "Contributors: michaelmenzel@google.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd02f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3883f6b-da6e-4bf7-b7f2-1ce89c073129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q matplotlib \\\n",
    "    google-cloud-aiplatform[autologging]==1.65.0 \\\n",
    "    tensorflow-datasets==4.9.6     keras==3.5.0 \\\n",
    "    keras-cv==0.9.0 tensorflow==2.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eec077b-5d3e-4b51-99f4-f627eae824a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_ID = '1850063553663336448'\n",
    "DATASET_EXPORT_BUCKET = 'gs://visual-inspection-demo-datasets-us-central1/car-damage-coco-segmentation-kaggle/vertexai-export/test'\n",
    "DATA_DIR = 'gs://visual-inspection-demo-datadir-us-central1'\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304804a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud storage buckets create --location $LOCATION $DATA_DIR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71861f-31eb-4bf5-b13f-c40ebc6e6396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "import keras_cv\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c81d95-bb8d-4de3-9304-42b9206f37d2",
   "metadata": {},
   "source": [
    "## Load Vertex AI Image Segmentation Dataset with TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6f630-2b09-4175-875d-fad7605cd8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "img_ds = aiplatform.ImageDataset(DATASET_ID, location=LOCATION)\n",
    "exported_img_ds = img_ds.export_data_for_custom_training(\n",
    "    DATASET_EXPORT_BUCKET,\n",
    "    annotation_schema_uri='gs://google-cloud-aiplatform/schema/dataset/annotation/image_segmentation_1.0.0.yaml',\n",
    "    split={ 'training_fraction': 0.8, 'validation_fraction': 0.1, 'test_fraction': 0.1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577fb75f-a638-4624-a3bc-d376d981efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_img_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8823105f-73b2-4354-b709-6ac594e3d258",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../trainer')\n",
    "from vertexai_image_segmentation_dataset import VertexAIImageSegmentationDataset\n",
    "\n",
    "(train_ds, val_ds, test_ds), info = VertexAIImageSegmentationDataset.load(\n",
    "    split=['train', 'validation', 'test'], with_info=True, as_supervised=True,\n",
    "    #data_dir=DATA_DIR, #currently not working with GCS in TFDS \n",
    "    builder_kwargs={\n",
    "        'training_data': exported_img_ds['exportedFiles'][0],\n",
    "        'validation_data': exported_img_ds['exportedFiles'][1],\n",
    "        'test_data': exported_img_ds['exportedFiles'][2],\n",
    "    })\n",
    "\n",
    "def prep_ds(ds):\n",
    "    return (ds\n",
    "            #.shuffle(ds.cardinality())\n",
    "            .batch(BATCH_SIZE, drop_remainder=True)\n",
    "            .map(lambda x,y: (x / 255, y / 255), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "           )\n",
    "\n",
    "train_ds, val_ds, test_ds = map(prep_ds, (train_ds, val_ds, test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f3ca3-b4f1-4731-9104-5e5dc7099dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test_ds.unbatch().take(1):\n",
    "    plt.imshow(x)\n",
    "    plt.show()\n",
    "    plt.imshow(y[:,:,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c52ef-0a6a-4551-b0e0-8d574a36223a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_ds = test_ds.unbatch().cache()\n",
    "\n",
    "keras_cv.visualization.plot_image_gallery(\n",
    "    np.array(list(plot_ds.take(1).map(lambda x,y: x).as_numpy_iterator())),\n",
    "    value_range=(0, 1), rows=1, cols=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb231ffa-0a1d-4d38-ab06-d4c70c47a407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = info.features['segmentation_mask'].shape[-1]\n",
    "IMAGE_SHAPE = info.features['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91f5f9-e07a-4abc-a24e-ef508a4f903b",
   "metadata": {},
   "source": [
    "## Train a DeepLabV3 Segmentation Model with Keras CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b501e75-cdcc-4aa2-a586-37cff1343d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras_cv.models.DeepLabV3Plus.from_preset(\n",
    "    \"efficientnetv2_b0_imagenet\",\n",
    "    num_classes=NUM_CLASSES,\n",
    "    input_shape=IMAGE_SHAPE,\n",
    ")\n",
    "model.compile(optimizer='adam', \n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f422476-be12-47e4-bebd-01614dbebb4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51f7c8-6add-43bd-96e0-014617ca0ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_examples = min(info.splits['test'].num_examples, 8)\n",
    "plot_ds = test_ds.unbatch().take(num_examples).cache()\n",
    "\n",
    "keras_cv.visualization.plot_segmentation_mask_gallery(\n",
    "    list(plot_ds.map(lambda x,y: x).as_numpy_iterator()),\n",
    "    (0, 1),\n",
    "    (NUM_CLASSES-1),\n",
    "    y_true=list(plot_ds.map(lambda x,y: tf.expand_dims(tf.argmax(y, axis=-1), axis=-1)).as_numpy_iterator()),\n",
    "    y_pred=list(plot_ds.map(lambda x,y: tf.expand_dims(tf.argmax(tf.squeeze(model(tf.expand_dims(x, axis=0))), axis=-1), axis=-1)).as_numpy_iterator()),\n",
    "    rows=1,\n",
    "    cols=num_examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e2cfd-5795-4ce0-b467-a34bb751604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds,\n",
    "    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1b44e-5401-47ff-a1ad-deec3700183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0325a-026b-4d4e-8182-3a165c22e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = min(info.splits['test'].num_examples, 8)\n",
    "plot_ds = test_ds.unbatch().take(num_examples).cache()\n",
    "\n",
    "keras_cv.visualization.plot_segmentation_mask_gallery(\n",
    "    list(plot_ds.map(lambda x,y: x).as_numpy_iterator()),\n",
    "    (0, 1),\n",
    "    (NUM_CLASSES-1),\n",
    "    y_true=list(plot_ds.map(lambda x,y: tf.expand_dims(tf.argmax(y, axis=-1), axis=-1)).as_numpy_iterator()),\n",
    "    y_pred=list(plot_ds.map(lambda x,y: tf.expand_dims(tf.argmax(tf.squeeze(model(tf.expand_dims(x, axis=0))), axis=-1), axis=-1)).as_numpy_iterator()),\n",
    "    rows=1,\n",
    "    cols=num_examples\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
