{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eec077b-5d3e-4b51-99f4-f627eae824a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define project id and location for the pipeline\n",
    "PROJECT_ID = 'visual-inspection-demo-2184'\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "# The dataset id in Vertex to use for model tests\n",
    "DATASET_ID = '1850063553663336448'\n",
    "# A GCP bucket to export the dataset\n",
    "DATASET_EXPORT_BUCKET = 'gs://visual-inspection-demo-datasets-us-central1/pixel-phone-damage-defects/vertexai-export/test/'\n",
    "\n",
    "# Model endpoint\n",
    "# if private endpoint make sure to run in the according VPC\n",
    "ENDPOINT = 'projects/1047381110578/locations/us-central1/endpoints/1567473672162115584'\n",
    "\n",
    "# Batch size to use with the model\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3883f6b-da6e-4bf7-b7f2-1ce89c073129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q matplotlib \\\n",
    "    google-cloud-aiplatform[autologging]==1.65.0 \\\n",
    "    tensorflow-datasets==4.9.6     keras==3.5.0 \\\n",
    "    keras-cv==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71861f-31eb-4bf5-b13f-c40ebc6e6396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "import keras_cv\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267b59e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='coolwarm')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "def prep_ds(ds):\n",
    "  return (ds\n",
    "          .batch(BATCH_SIZE, drop_remainder=True)\n",
    "          .map(lambda x,y: (x / 255, y / 255),\n",
    "               num_parallel_calls=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c81d95-bb8d-4de3-9304-42b9206f37d2",
   "metadata": {},
   "source": [
    "## Load Vertex AI Image Segmentation Dataset with TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6f630-2b09-4175-875d-fad7605cd8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "img_ds = aiplatform.ImageDataset(DATASET_ID, location=LOCATION)\n",
    "exported_img_ds = img_ds.export_data_for_custom_training(\n",
    "    DATASET_EXPORT_BUCKET,\n",
    "    annotation_schema_uri='gs://google-cloud-aiplatform/schema/dataset/annotation/image_segmentation_1.0.0.yaml',\n",
    "    split={ 'training_fraction': 0.8, 'validation_fraction': 0.1, 'test_fraction': 0.1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577fb75f-a638-4624-a3bc-d376d981efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_img_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823105f-73b2-4354-b709-6ac594e3d258",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trainer.vertexai_image_segmentation_dataset import VertexAIImageSegmentationDataset\n",
    "\n",
    "(train_ds, val_ds, test_ds), info = VertexAIImageSegmentationDataset.load(\n",
    "    split=['train', 'validation', 'test'], with_info=True, as_supervised=True,\n",
    "    #data_dir=DATA_DIR, #currently not working with GCS in TFDS \n",
    "    builder_kwargs={\n",
    "        'training_data': exported_img_ds['exportedFiles'][0],\n",
    "        'validation_data': exported_img_ds['exportedFiles'][1],\n",
    "        'test_data': exported_img_ds['exportedFiles'][2],\n",
    "    })\n",
    "\n",
    "train_ds, val_ds, test_ds = map(prep_ds, (train_ds, val_ds, test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f3ca3-b4f1-4731-9104-5e5dc7099dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb231ffa-0a1d-4d38-ab06-d4c70c47a407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = info.features['segmentation_mask'].shape[-1]\n",
    "IMAGE_SHAPE = info.features['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cdd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 8\n",
    "plot_ds = train_ds.unbatch().take(examples).cache()\n",
    "\n",
    "keras_cv.visualization.plot_segmentation_mask_gallery(\n",
    "    list(plot_ds.map(lambda x,y: x).as_numpy_iterator()),\n",
    "    (0, 1),\n",
    "    NUM_CLASSES,\n",
    "    y_true=list(plot_ds.map(lambda x,y: tf.expand_dims(tf.argmax(y, axis=-1), axis=-1)).as_numpy_iterator()),\n",
    "    rows=2,\n",
    "    cols=4,\n",
    "    scale=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a8d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "examples = list(plot_ds.map(lambda x,y: (x, tf.expand_dims(tf.argmax(y, axis=-1), axis=-1))).as_numpy_iterator())\n",
    "for ex in examples:\n",
    "    display(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6e7339",
   "metadata": {},
   "source": [
    "## Connect to Model Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d33b84",
   "metadata": {},
   "source": [
    "Private endpoints require extra network setup, but allow for workloads\n",
    "larger than 1.5 MB. For most use cases images are larger than 1.5 MB.\n",
    "\n",
    "Read more: https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "557c52ef-0a6a-4551-b0e0-8d574a36223a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_endpoint = aiplatform.PrivateEndpoint(ENDPOINT)\n",
    "# or use a public endpoint with a limit of 1.5 MB per request:\n",
    "# model_endpoint = aiplatform.Endpoint(ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe222cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test_ds.unbatch().batch(1).take(1).as_numpy_iterator():\n",
    "    print(model_endpoint.predict(x.tolist()).predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51f7c8-6add-43bd-96e0-014617ca0ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples = 2\n",
    "plot_ds = test_ds.unbatch().take(examples).cache()\n",
    "\n",
    "keras_cv.visualization.plot_segmentation_mask_gallery(\n",
    "    list(plot_ds.map(lambda x,y: x).as_numpy_iterator()),\n",
    "    (0, 1),\n",
    "    NUM_CLASSES-1,\n",
    "    y_true=list(plot_ds.map(lambda x,y: tf.expand_dims(tf.argmax(y, axis=-1), axis=-1)).as_numpy_iterator()),\n",
    "    y_pred=list(plot_ds.map(lambda x,y: tf.expand_dims(tf.squeeze(tf.argmax(model_endpoint.predict(tf.expand_dims(x, axis=0).numpy().tolist()).predictions, axis=-1)), axis=-1)).as_numpy_iterator()),\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    scale=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c117c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = list(plot_ds.map(lambda x,y: (x, \n",
    "                                         tf.expand_dims(\n",
    "                                            tf.argmax(y, axis=-1), axis=-1),\n",
    "                                         tf.expand_dims(\n",
    "                                            tf.squeeze(\n",
    "                                                tf.argmax(\n",
    "                                                    model_endpoint.predict(\n",
    "                                                        tf.expand_dims(x, axis=0).numpy().tolist()\n",
    "                                                        ).predictions, \n",
    "                                                           axis=-1)), \n",
    "                                                axis=-1)\n",
    "                                        )\n",
    "                            ).as_numpy_iterator())\n",
    "for ex in examples:\n",
    "    display(ex)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
