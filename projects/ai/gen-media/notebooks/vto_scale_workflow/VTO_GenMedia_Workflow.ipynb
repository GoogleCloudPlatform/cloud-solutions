{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a92bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright 2025 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B9SgWpCruX5g",
   "metadata": {
    "id": "B9SgWpCruX5g"
   },
   "source": [
    "# Gen Media end-to-end Workflow, Virtual Try-on usecase\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/cloud-solutions/blob/main/projects/ai/gen-media/notebooks/vto_scale_workflow/VTO_GenMedia_Workflow.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fcloud-solutions%2Fmain%2Fprojects%2Fai%2Fgen-media%2Fnotebooks%2Fvto_scale_workflow%2FVTO_GenMedia_Workflow.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/cloud-solutions/main/projects/ai/gen-media/notebooks/vto_scale_workflow/VTO_GenMedia_Workflow.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/cloud-solutions/tree/main/projects/ai/gen-media/notebooks/vto_scale_workflow\">\n",
    "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br clear=\"all\">\n",
    "\n",
    "| Author |\n",
    "| --- |\n",
    "| [Layolin Jesudhass](layolin@google.com) |\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Jupyter Notebook outlines a complete, scalable pipeline for generating diverse, photorealistic virtual try-on. The core objective is to use a suite of Google's Generative AI modelsâ€”Gemini (for orchestration and critique), Gemini Image Generation (for creating diverse base models), Vertex AI Virtual Try-On (VTO) (for garment swapping), and Veo (for adding motion)â€”to produce a large volume of Virtual Try-On images and short motion videos featuring diverse digital models in various outfits. All these are created using one platform Vertex AI!\n",
    "\n",
    "## Prerequisites - Preparing Your GCS Bucket\n",
    "\n",
    "Before running this notebook end-to-end, you need to copy the sample dress images to your Google Cloud Storage bucket:\n",
    "\n",
    "1. **Copy Sample Dress Images**: The sample dress images are provided in the `dress/` folder. Copy these files to your GCS bucket under the path specified by `OUTFITS_PREFIX` (which is set to \"dress\" by default):\n",
    "\n",
    "   ```bash\n",
    "   # Example command to copy images from the local dress folder to your GCS bucket\n",
    "   gsutil cp dress/*.png gs://YOUR_BUCKET_NAME/dress/\n",
    "   ```\n",
    "\n",
    "   The notebook expects dress images to be available at: `gs://YOUR_BUCKET_NAME/dress/`\n",
    "\n",
    "   Note: The `OUTFITS_PREFIX = \"dress\"` variable in the configuration section defines where the notebook looks for input dress images.\n",
    "\n",
    "2. **Update Configuration**: In the Global Configuration section below, update:\n",
    "   - `PROJECT_ID`: Your Google Cloud Project ID\n",
    "   - `BUCKET_NAME`: Your Google Cloud Storage bucket name\n",
    "   - `LOCATION`: Your preferred region (default: us-central1)\n",
    "\n",
    "Created on 11/12/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FReTKQdaeFis",
   "metadata": {
    "id": "FReTKQdaeFis"
   },
   "source": [
    "#Imports and Dependencies\n",
    "\n",
    "Below cell includes all necessary standard library (e.g., os, sys, re), third-party (pandas, PIL), and Google Cloud (google.genai, google.cloud.storage) imports required to run the workflow.\n",
    "\n",
    "\n",
    "*   Import standard Python libraries for file operations, regular expressions, data handling, and time.\n",
    "*   Import third-party libraries like pandas for data manipulation and PIL (Pillow) for image processing.\n",
    "*   Import Google Cloud libraries for interacting with Google Cloud Storage (storage) and Vertex AI (PredictionServiceClient).\n",
    "*   Import Google Generative AI SDK components (google.genai, types) to interface with Gemini and Veo models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FMZAhY8DuYTC",
   "metadata": {
    "id": "FMZAhY8DuYTC"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import base64\n",
    "import concurrent.futures\n",
    "import csv\n",
    "import datetime as dt\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "import uuid\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, wait\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# Third-party\n",
    "import pandas as pd\n",
    "\n",
    "# Google Cloud & GenAI\n",
    "from google import genai\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform.gapic import PredictionServiceClient\n",
    "from google.genai import types\n",
    "from google.genai.types import (\n",
    "    GenerateContentConfig,\n",
    "    GenerateVideosConfig,\n",
    ")\n",
    "from google.genai.types import Image as GenAIImage\n",
    "from google.genai.types import (\n",
    "    Modality,\n",
    "    Part,\n",
    ")\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nbdo05_pvczV",
   "metadata": {
    "id": "Nbdo05_pvczV"
   },
   "source": [
    "# Update for model changes happens here\n",
    "\n",
    "All configurable parameters (Project ID, Bucket Names, Model Versions, Paths) are centralized here. Standardized the bucket variable to BUCKET_NAME across the script.\n",
    "\n",
    "\n",
    "*   List itemCentralize all configurable parameters, including Google Cloud Project ID and location.List item\n",
    "*   Define GCS bucket details and file path prefixes for managing various assets (model images, outfit images, VTO outputs, and final videos).\n",
    "*   Specify the exact model versions\n",
    "*   Initialize the necessary Python clients for Google Cloud Storage and the Generative AI API.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RFIBaIo8uZyl",
   "metadata": {
    "id": "RFIBaIo8uZyl"
   },
   "outputs": [],
   "source": [
    "# Global Configuration, UPDATE FOR ANY MODEL CHANGES\n",
    "# --- Project & Location Settings ---\n",
    "# Ensure these match your environment\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"PROJECT_ID\"  # update your project\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"  # update your location\n",
    "\n",
    "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_LOCATION\")\n",
    "GENAI_LOCATION = \"us-central1\"  # or \"global\" depending on availability\n",
    "\n",
    "# --- Storage Configuration ---\n",
    "BUCKET_NAME = \"BUCKET_NAME_PLACEHOLDER\"  # Standardized bucket name , update your bucket name\n",
    "\n",
    "# GCS Paths/Prefixes -> The process will create the subsequent file and folder structure\n",
    "CSV_OBJECT_NAME = \"Model_Creation.csv\"\n",
    "MODELS_PREFIX = \"models\"  # Base images of models\n",
    "OUTFITS_PREFIX = \"dress\"  # Input dress images\n",
    "VTO_OUTPUT_PREFIX = \"dress/4tryon\"\n",
    "FINAL_PREFIX = \"dress/4tryon/final\"\n",
    "MOTION_OUTPUT_PREFIX = \"dress/4tryon/final_motion\"\n",
    "\n",
    "# --- Model Versions ---\n",
    "# Text/Orchestration Model\n",
    "MODEL_TEXT = \"gemini-2.5-flash\"\n",
    "\n",
    "# Image Generation Model\n",
    "MODEL_IMAGE_GEN = \"gemini-2.5-flash-image\"\n",
    "\n",
    "# Virtual Try-On (Vertex AI)\n",
    "MODEL_ID_VTO = \"virtual-try-on-001\"\n",
    "\n",
    "# Video Generation (Veo)\n",
    "MODEL_VIDEO = \"veo-3.0-generate-001\"\n",
    "\n",
    "# --- Execution Parameters ---\n",
    "NUM_MODELS_TO_GENERATE = 5\n",
    "PARALLEL_JOBS_PER_MODEL = 10\n",
    "VTO_VARIATIONS = 4  # Number of images per try-on\n",
    "\n",
    "# Initialize Global Clients\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "genai_client = genai.Client(\n",
    "    vertexai=True, project=PROJECT_ID, location=GENAI_LOCATION\n",
    ")\n",
    "\n",
    "print(f\"Configuration Set: Project={PROJECT_ID}, Bucket={BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FdXuyDT1vrkn",
   "metadata": {
    "id": "FdXuyDT1vrkn"
   },
   "source": [
    "#Use Case 1 - Model Definitions (CSV Generation)\n",
    "\n",
    "Description: Logic to generate the CSV file containing diverse model prompts.\n",
    "\n",
    "- Define a comprehensive list of diversity parameters (Ethnicity, Age, Skin Tone, Body Type, Hair Style).\n",
    "\n",
    "- Define a rigid output structure (JSON Schema) to ensure the model's response is machine-readable and includes Title, Distinctive Traits, and the full image Description.\n",
    "\n",
    "- Use Gemini Flash (orchestration model) with a constrained output schema to generate NUM_MODELS_TO_GENERATE (e.g., 5) unique, diverse model prompts.\n",
    "\n",
    "Convert the structured response into a raw CSV string.\n",
    "\n",
    "- Upload the Model_Creation.csv file containing the generated prompts to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T0wg6bkpuZ1-",
   "metadata": {
    "id": "T0wg6bkpuZ1-"
   },
   "outputs": [],
   "source": [
    "# ===== Diversity Parameters and Template =====\n",
    "DIVERSITY_INSTRUCTIONS = \"\"\"\n",
    "Ethnicity: African American, Afro-Caribbean, East African, West African, East Asian, South Asian, Southeast Asian, Middle Eastern,\n",
    "Pacific Islander, Native American, Indigenous Australian, Caucasian, Eastern European, Irish, Mixed-race, Inuit.\n",
    "Age: young adult, adult, middle-aged, elderly.\n",
    "Skin Tone: porcelain, fair, olive, tan, golden-brown, caramel, deep brown, ebony, cool beige, dusky.\n",
    "Body Type: petite, athletic, curvy, plus-size, triple-plus-size, tall and lean, average, full-figured, slender, compact, statuesque.\n",
    "Hair Style: long black hair, short natural curls, long blonde hair, wavy brown hair, shoulder-length black hair, auburn hair, long red hair,\n",
    "straight dark hair, natural curls, short silver hair, tightly coiled short hair.\n",
    "\n",
    "The full description template is:\n",
    "\"A full-body studio photo of a {age} {ethnicity} woman with {skin} skin and a {body} build {hair_clause}.\n",
    "Outfit: plain white shirt, blue jeans, and white sneakers (same style for all). Background: plain white; neutral lighting; front-facing; natural posture; no accessories, logos, text, or props.\"\n",
    "The {hair_clause} must be derived from the 'Hair Style' list and formatted as ', [hair style]'.\n",
    "\"\"\"\n",
    "\n",
    "CSV_SCHEMA = types.Schema(\n",
    "    type=types.Type.ARRAY,\n",
    "    description=f\"A list of {{NUM_MODELS_TO_GENERATE}} unique model definitions.\",  # Placeholder replacement for demonstration\n",
    "    items=types.Schema(\n",
    "        type=types.Type.OBJECT,\n",
    "        properties={\n",
    "            \"Title\": types.Schema(\n",
    "                type=types.Type.STRING,\n",
    "                description=\"A brief title, e.g., 'Plus-Size East Asian Woman'.\",\n",
    "            ),\n",
    "            \"Distinctive Traits\": types.Schema(\n",
    "                type=types.Type.STRING,\n",
    "                description=\"A summary of the model's traits.\",\n",
    "            ),\n",
    "            \"Description\": types.Schema(\n",
    "                type=types.Type.STRING,\n",
    "                description=\"The full, detailed text prompt following the template provided.\",\n",
    "            ),\n",
    "        },\n",
    "        required=[\"Title\", \"Distinctive Traits\", \"Description\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def generate_csv_data_with_gemini(n_rows: int) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Generates diverse model prompts and returns both the raw CSV string\n",
    "    and a formatted Markdown table string.\n",
    "    \"\"\"\n",
    "    system_instruction = (\n",
    "        \"You are an expert prompt engineer generating a diverse list of models for \"\n",
    "        \"AI image creation. You must strictly adhere to the provided lists and template. \"\n",
    "        \"The goal is to maximize diversity across all listed categories for each of the \"\n",
    "        f\"{n_rows} rows. Provide the final output as a CSV string.\"\n",
    "    )\n",
    "    prompt = (\n",
    "        f\"Generate {n_rows} unique, diverse entries for image generation prompts. \"\n",
    "        \"Each entry must strictly select characteristics from the following lists:\\n\\n\"\n",
    "        f\"{DIVERSITY_INSTRUCTIONS}\\n\\n\"\n",
    "        \"Generate the data in a CSV format with the following columns: 'Title', 'Distinctive Traits', 'Description'.\"\n",
    "    )\n",
    "\n",
    "    response = genai_client.models.generate_content(\n",
    "        model=MODEL_TEXT,\n",
    "        contents=[prompt],\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=system_instruction,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=CSV_SCHEMA,\n",
    "            temperature=0.7,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    data = pd.read_json(io.StringIO(response.text))\n",
    "\n",
    "    # 1. Generate Raw CSV text (for upload)\n",
    "    csv_buf = io.StringIO()\n",
    "    data.to_csv(csv_buf, index=False, encoding=\"utf-8\")\n",
    "    csv_text = csv_buf.getvalue()\n",
    "\n",
    "    # 2. Generate Markdown Table text (for display)\n",
    "    markdown_text = data.to_markdown(index=False, tablefmt=\"simple\")\n",
    "\n",
    "    return csv_text, markdown_text\n",
    "\n",
    "\n",
    "def upload_csv_text_to_gcs(csv_text: str):\n",
    "    blob = storage_client.bucket(BUCKET_NAME).blob(CSV_OBJECT_NAME)\n",
    "    blob.upload_from_string(csv_text, content_type=\"text/csv; charset=utf-8\")\n",
    "    print(f\"[OK] Uploaded CSV to gs://{BUCKET_NAME}/{CSV_OBJECT_NAME}\")\n",
    "\n",
    "\n",
    "# Execution\n",
    "csv_text, table_text = generate_csv_data_with_gemini(NUM_MODELS_TO_GENERATE)\n",
    "# --- Display the results in table format ---\n",
    "print(\"Generated Model Prompts\")\n",
    "print(table_text)\n",
    "# --- Upload the original CSV text to GCS ---\n",
    "upload_csv_text_to_gcs(csv_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jJBe_EcUv_iO",
   "metadata": {
    "id": "jJBe_EcUv_iO"
   },
   "source": [
    "#Use Case 2 - Model Image Generation\n",
    "\n",
    "Description: Reads the CSV generated in the previous step and uses Gemini Image Generation aka Nano Banana to create the base model images.\n",
    "\n",
    "- Define the STYLE_INSTRUCTION to maintain a consistent look for all models (e.g., specific white t-shirt, black jeans, white background).\n",
    "\n",
    "- Read the Model_Creation.csv file from GCS into a DataFrame.\n",
    "\n",
    "- Iterate through each model prompt (Description) from the CSV.\n",
    "\n",
    "- Combine the fixed STYLE_INSTRUCTION and the diverse Description into a final image generation prompt.\n",
    "\n",
    "- Call the Gemini Image Generation Model (Nano Banana) to create a full-body image for each diverse model.\n",
    "\n",
    "- Upload each generated image to GCS under the models prefix.\n",
    "\n",
    "- Display the generated images directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I6qEl-MguZ4T",
   "metadata": {
    "id": "I6qEl-MguZ4T"
   },
   "outputs": [],
   "source": [
    "PROMPT_COLUMN = \"Description\"\n",
    "IDENTIFIER_COLUMNS = [\"Title\"]\n",
    "\n",
    "STYLE_INSTRUCTION = (\n",
    "    \"Render a full-body studio photo of the described person with the following fixed styling:\\n\"\n",
    "    \"- Outfit: plain white round neck t-shirt, classic black jeans, and white casual sneakers.\\n\"\n",
    "    \"- IMPORTANT :same style for every model, keep the t-shirt completly inserted.\\n\"\n",
    "    \"- Styling: Make sure all models are styled the same way.\\n\"\n",
    "    \"- Background: plain solid white background, no props, no text.\\n\"\n",
    "    \"- Lighting: neutral and even; avoid hard shadows.\\n\"\n",
    "    \"- Pose: simple front-facing stance; natural posture; no accessories or logos.\\n\"\n",
    "    \"- Keep the personâ€™s body type, skin tone, age, and ethnicity exactly as described below.\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "def read_csv_gs(bucket, object_name) -> pd.DataFrame:\n",
    "    blob = storage_client.bucket(bucket).blob(object_name)\n",
    "    data = blob.download_as_bytes()\n",
    "    return pd.read_csv(io.BytesIO(data))\n",
    "\n",
    "\n",
    "def sanitize(s: str) -> str:\n",
    "    clean = (\n",
    "        \"\".join(ch if ch.isalnum() else \"_\" for ch in str(s)).strip(\"_\").lower()\n",
    "    )\n",
    "    while \"__\" in clean:\n",
    "        clean = clean.replace(\"__\", \"_\")\n",
    "    return clean[:64] or \"image\"\n",
    "\n",
    "\n",
    "def gen_image_bytes(prompt_text: str) -> Optional[bytes]:\n",
    "    try:\n",
    "        resp = genai_client.models.generate_content(\n",
    "            model=MODEL_IMAGE_GEN,\n",
    "            contents=(prompt_text,),\n",
    "            config=GenerateContentConfig(\n",
    "                response_modalities=[Modality.TEXT, Modality.IMAGE]\n",
    "            ),\n",
    "        )\n",
    "        for part in resp.candidates[0].content.parts:\n",
    "            if part.inline_data and part.inline_data.data:\n",
    "                return part.inline_data.data\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"  [ERROR] Generation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def upload_png(image_bytes: bytes, stem: str) -> str:\n",
    "    ts = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    uid = uuid.uuid4().hex[:8]\n",
    "    name = f\"{MODELS_PREFIX}/{sanitize(stem)}_stdfit_{ts}_{uid}.png\"\n",
    "    blob = storage_client.bucket(BUCKET_NAME).blob(name)\n",
    "    blob.upload_from_string(image_bytes, content_type=\"image/png\")\n",
    "    # Return the GCS URI\n",
    "    return f\"gs://{BUCKET_NAME}/{name}\"\n",
    "\n",
    "\n",
    "# ---  FUNCTION FOR DISPLAY ---\n",
    "def display_images_in_row(\n",
    "    gcs_uris: list[str], bucket_name: str, total_cols: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Displays images side-by-side in a Colab notebook by downloading image bytes\n",
    "    from GCS and embedding them directly in HTML using Base64 encoding.\n",
    "    This bypasses all Public Access Prevention and Signed URL issues.\n",
    "    \"\"\"\n",
    "    if not gcs_uris:\n",
    "        print(\"No images to display.\")\n",
    "        return\n",
    "\n",
    "    container_width = 100 / total_cols\n",
    "    images_html = []\n",
    "\n",
    "    for uri in gcs_uris:\n",
    "        try:\n",
    "            # 1. Extract the blob name\n",
    "            blob_name = uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "            blob = storage_client.bucket(bucket_name).blob(blob_name)\n",
    "\n",
    "            # 2. Download the image bytes directly\n",
    "            image_bytes = blob.download_as_bytes()\n",
    "\n",
    "            # 3. Encode the bytes as Base64 for HTML embedding\n",
    "            encoded_image = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "            # 4. Create the Data URI\n",
    "            data_uri = f\"data:image/png;base64,{encoded_image}\"\n",
    "\n",
    "            # Create HTML for one image container\n",
    "            img_html = f\"\"\"\n",
    "            <div style=\"width: {container_width}%; box-sizing: border-box; padding: 5px; text-align: center;\">\n",
    "                <img src=\"{data_uri}\" style=\"width: 100%; height: auto; border: 1px solid #ccc;\"/>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            images_html.append(img_html)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] Failed to process or display {uri}: {e}\")\n",
    "\n",
    "    # Combine all image containers into a single row\n",
    "    full_html = f\"\"\"\n",
    "    <div style=\"display: flex; flex-direction: row; flex-wrap: nowrap; overflow-x: auto; width: 100%;\">\n",
    "        {''.join(images_html)}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    display(HTML(full_html))\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "print(f\"\\n[Start] Generating Models from CSV...\")\n",
    "try:\n",
    "    df = read_csv_gs(BUCKET_NAME, CSV_OBJECT_NAME)\n",
    "\n",
    "    num_models = (\n",
    "        NUM_MODELS_TO_GENERATE\n",
    "        if \"NUM_MODELS_TO_GENERATE\" in locals()\n",
    "        else len(df)\n",
    "    )\n",
    "    df = df.head(num_models)\n",
    "\n",
    "    generated_uris = []\n",
    "    for i, row in df.iterrows():\n",
    "        title = str(row.get(\"Title\", f\"row_{i+1}\")).strip()\n",
    "        desc = row.get(PROMPT_COLUMN)\n",
    "\n",
    "        stem = f\"model_{sanitize(title)}\"\n",
    "        prompt_text = f\"{STYLE_INSTRUCTION}\\n--- Person Description ---\\n{desc}\"\n",
    "\n",
    "        img = gen_image_bytes(prompt_text)\n",
    "        if img:\n",
    "            uri = upload_png(img, stem)\n",
    "            generated_uris.append(uri)\n",
    "        else:\n",
    "            print(\"  [Fail] No image generated.\")\n",
    "\n",
    "    print(f\"\\n[Total] Generated & uploaded: {len(generated_uris)} image(s).\")\n",
    "\n",
    "    # ---  DISPLAY CALL ---\n",
    "    print(\"\\n[Display] Displaying generated images in a row...\")\n",
    "    display_images_in_row(\n",
    "        generated_uris, BUCKET_NAME, total_cols=len(generated_uris)\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[FATAL ERROR] {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JBcS4bb5wLjf",
   "metadata": {
    "id": "JBcS4bb5wLjf"
   },
   "source": [
    "#Use Case 3 - Virtual Try-On (Vertex AI VTO)\n",
    "\n",
    "Description: Multi-try-on in one shot using the Vertex AI VTO API\n",
    "- The process involves pairing the generated model images (from Step 4) with input outfit images (from the GCS dress prefix).\n",
    "\n",
    "- Use a ThreadPoolExecutor to orchestrate the VTO generation in parallel for multiple model/outfit pairs.\n",
    "\n",
    "- Call the Vertex AI VTO Model  for each pair, generating a defined number of candidate try-on images (VTO_VARIATIONS = 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rjJd-Kq2uZ90",
   "metadata": {
    "id": "rjJd-Kq2uZ90"
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "\n",
    "def b64(data: bytes) -> str:\n",
    "    return base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def list_top_level_pngs(bucket_name, prefix) -> List[str]:\n",
    "    blobs = storage_client.list_blobs(\n",
    "        bucket_name, prefix=prefix if prefix.endswith(\"/\") else prefix + \"/\"\n",
    "    )\n",
    "    names = [\n",
    "        b.name\n",
    "        for b in blobs\n",
    "        if b.name.lower().endswith(\".png\")\n",
    "        and \"/\" not in b.name[len(prefix) + 1 :]\n",
    "    ]\n",
    "    names.sort()\n",
    "    return names\n",
    "\n",
    "\n",
    "def pil_from_prediction(pred) -> Image.Image:\n",
    "    encoded = pred[\"bytesBase64Encoded\"]\n",
    "    return Image.open(io.BytesIO(base64.b64decode(encoded))).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def call_virtual_try_on_4(\n",
    "    person_b64: str, outfit_b64: str\n",
    ") -> List[Image.Image]:\n",
    "    client = PredictionServiceClient(\n",
    "        client_options={\"api_endpoint\": f\"{LOCATION}-aiplatform.googleapis.com\"}\n",
    "    )\n",
    "    instances = [\n",
    "        {\n",
    "            \"personImage\": {\"image\": {\"bytesBase64Encoded\": person_b64}},\n",
    "            \"productImages\": [{\"image\": {\"bytesBase64Encoded\": outfit_b64}}],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    params = {\"experimentalMode\": \"exp-08-04\", \"sampleCount\": VTO_VARIATIONS}\n",
    "    resp = client.predict(\n",
    "        endpoint=f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{MODEL_ID_VTO}\",\n",
    "        instances=instances,\n",
    "        parameters=params,\n",
    "    )\n",
    "    return [pil_from_prediction(p) for p in resp.predictions]\n",
    "\n",
    "\n",
    "def tryon_worker(\n",
    "    model_name: str, person_b64: str, outfit_path: str, retries: int = 3\n",
    "):\n",
    "    outfit_name = os.path.splitext(os.path.basename(outfit_path))[0]\n",
    "\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            outfit_bytes = (\n",
    "                storage_client.bucket(BUCKET_NAME)\n",
    "                .blob(outfit_path)\n",
    "                .download_as_bytes()\n",
    "            )\n",
    "            imgs = call_virtual_try_on_4(person_b64, b64(outfit_bytes))\n",
    "\n",
    "            # Save each candidate PNG\n",
    "            for idx, img in enumerate(imgs):\n",
    "                buf = io.BytesIO()\n",
    "                img.save(buf, format=\"PNG\")\n",
    "                out_rel = f\"{VTO_OUTPUT_PREFIX}/{model_name}_TRYON4_{outfit_name}_C{idx+1}.png\"\n",
    "                storage_client.bucket(BUCKET_NAME).blob(\n",
    "                    out_rel\n",
    "                ).upload_from_string(buf.getvalue(), content_type=\"image/png\")\n",
    "\n",
    "            print(f\"[DONE] {model_name} x {outfit_name}\")\n",
    "            return True  # success, stop retry loop\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"[ERROR] {model_name} x {outfit_name} (attempt {attempt}): {e}\"\n",
    "            )\n",
    "            if attempt == retries:\n",
    "                print(\n",
    "                    f\"[FAIL] {model_name} x {outfit_name} failed after {retries} attempts.\"\n",
    "                )\n",
    "                return False  # failed after all retries\n",
    "\n",
    "\n",
    "# Execution\n",
    "print(f\"\\n[START VTO] Vertex AI \")\n",
    "outfit_paths = list_top_level_pngs(BUCKET_NAME, OUTFITS_PREFIX)\n",
    "model_paths = list_top_level_pngs(BUCKET_NAME, MODELS_PREFIX)\n",
    "\n",
    "for model_path in model_paths:\n",
    "    model_name = os.path.splitext(os.path.basename(model_path))[0]\n",
    "\n",
    "    try:\n",
    "        person_bytes = (\n",
    "            storage_client.bucket(BUCKET_NAME)\n",
    "            .blob(model_path)\n",
    "            .download_as_bytes()\n",
    "        )\n",
    "        person_b64 = b64(person_bytes)\n",
    "\n",
    "        # 1st pass\n",
    "        failed = []\n",
    "        with ThreadPoolExecutor(\n",
    "            max_workers=min(PARALLEL_JOBS_PER_MODEL, len(outfit_paths))\n",
    "        ) as ex:\n",
    "            futures = {\n",
    "                ex.submit(tryon_worker, model_name, person_b64, p): p\n",
    "                for p in outfit_paths\n",
    "            }\n",
    "            for fut in as_completed(futures):\n",
    "                if fut.result() is False:\n",
    "                    failed.append(futures[fut])\n",
    "\n",
    "        # Retry only failed outfits\n",
    "        if failed:\n",
    "            print(\n",
    "                f\"\\n[RETRY PASS] Re-running {len(failed)} failed outfits for {model_name}...\"\n",
    "            )\n",
    "            with ThreadPoolExecutor(\n",
    "                max_workers=min(PARALLEL_JOBS_PER_MODEL, len(failed))\n",
    "            ) as ex:\n",
    "                futures = [\n",
    "                    ex.submit(tryon_worker, model_name, person_b64, p)\n",
    "                    for p in failed\n",
    "                ]\n",
    "                for fut in as_completed(futures):\n",
    "                    fut.result()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed processing model {model_path}: {e}\")\n",
    "\n",
    "print(f\"[DONE] Outputs in: gs://{BUCKET_NAME}/{VTO_OUTPUT_PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QaVTCIINx8JZ",
   "metadata": {
    "id": "QaVTCIINx8JZ"
   },
   "source": [
    "#Use Case 4 - AI Critique & Selection\n",
    "\n",
    "Description: Uses Gemini Flash to critique the 4 generated options and select the best one based on realism, fidelity, and artifact checking. Creates Evluation Summary with reason for the final pick.\n",
    "- Collect and group all VTO candidate images, ensuring exactly 4 candidates exist for each model/outfit combination.\n",
    "\n",
    "- Define the judge function that uses the Gemini Text Model (gemini flash) for a multi-modal critique.\n",
    "\n",
    "- The function inputs the original model image, the original outfit image, and the four VTO candidate images to the model.\n",
    "\n",
    "- The model determines the best image based on the quality of the try-on, realism, and adherence to the model's identity.\n",
    "\n",
    "- Execute the critique process in parallel using a ThreadPoolExecutor.\n",
    "\n",
    "- The winning image for each model/outfit combination is copied to the final GCS folder (dress/4tryon/final)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SehmdW6_x_q9",
   "metadata": {
    "id": "SehmdW6_x_q9"
   },
   "outputs": [],
   "source": [
    "print(\"[START] AI Critique\")\n",
    "\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "# --------- 1) Candidate Filename Pattern ---------\n",
    "CAND_RE = re.compile(\n",
    "    r\"^(?P<modelStamp>.+?)_TRYON4(?:_)?(?P<outfit>.+?)_C(?P<cid>[1-4])\\.png$\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "# --------- 2) Prompt ---------\n",
    "\n",
    "\n",
    "def build_critique_prompt(outfit, model_stamp):\n",
    "    return (\n",
    "        f\"**Target Outfit:** {outfit}\\n\"\n",
    "        f\"**Target Model:** {model_stamp}\\n\\n\"\n",
    "        \"You are a strict and highly critical visual judge for Virtual Try-On (VTO) quality.\\n\"\n",
    "        \"Select the SINGLE best try-on result where the outfit is transferred cleanly.\\n\"\n",
    "        \"The winning candidate MUST NOT show any part of the model's original clothing.\\n\"\n",
    "        \"The winning candidate MUST have both legs with shoe on.\\n\"\n",
    "        \"Judge based on: Garment Fidelity, Fit Realism, Clarity, and Lack of Artifacts.\\n\\n\"\n",
    "        \"Return JSON only:\\n\"\n",
    "        \"{ 'scores': { ... }, 'winner': 'C1|C2|C3|C4', 'reason_short': '...' }\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --------- 3) Judge function ---------\n",
    "\n",
    "\n",
    "def judge(cpaths, model_path, outfit_path):\n",
    "    b = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "    prompt = build_critique_prompt(\n",
    "        os.path.basename(outfit_path), os.path.basename(model_path)\n",
    "    )\n",
    "\n",
    "    parts = [prompt]\n",
    "\n",
    "    # Candidate images C1..C4 (correct Part.from_bytes signature)\n",
    "    for key in (\"C1\", \"C2\", \"C3\", \"C4\"):\n",
    "        parts.append(\n",
    "            Part.from_bytes(\n",
    "                mime_type=\"image/png\",\n",
    "                data=b.blob(cpaths[key]).download_as_bytes(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Reference model image\n",
    "    parts.append(\n",
    "        Part.from_bytes(\n",
    "            mime_type=\"image/png\", data=b.blob(model_path).download_as_bytes()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Reference outfit image\n",
    "    parts.append(\n",
    "        Part.from_bytes(\n",
    "            mime_type=\"image/png\", data=b.blob(outfit_path).download_as_bytes()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Critique call\n",
    "    resp = genai_client.models.generate_content(\n",
    "        model=MODEL_TEXT,\n",
    "        contents=parts,\n",
    "        config=GenerateContentConfig(\n",
    "            temperature=0.0, response_mime_type=\"application/json\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    text = getattr(resp, \"text\", None)\n",
    "    if not text:\n",
    "        text = resp.candidates[0].content.parts[0].text\n",
    "\n",
    "    data = json.loads(text)\n",
    "    return data.get(\"winner\", \"C1\"), data.get(\"reason_short\", \"\")\n",
    "\n",
    "\n",
    "# ---------  Display CSV Summary ---------\n",
    "\n",
    "\n",
    "def display_csv_summary(bucket_name: str, final_prefix: str):\n",
    "    \"\"\"\n",
    "    Reads the final evaluation summary CSV from GCS and displays it as a formatted\n",
    "    Markdown table using pandas.\n",
    "    \"\"\"\n",
    "    csv_object_name = f\"{final_prefix}/eval_summary.csv\"\n",
    "    print(\n",
    "        f\"\\n[START DISPLAY] Reading CSV from gs://{bucket_name}/{csv_object_name}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Read the blob content\n",
    "        blob = storage_client.bucket(bucket_name).blob(csv_object_name)\n",
    "        data = blob.download_as_bytes()\n",
    "\n",
    "        # Load into pandas DataFrame\n",
    "        df = pd.read_csv(io.BytesIO(data))\n",
    "\n",
    "        # Clean up column names and path\n",
    "        df[\"model\"] = (\n",
    "            df[\"model\"]\n",
    "            .str.replace(\"model_\", \"\")\n",
    "            .str.replace(\"_\", \" \")\n",
    "            .str.title()\n",
    "        )\n",
    "        df[\"outfit\"] = (\n",
    "            df[\"outfit\"]\n",
    "            .str.replace(\"outfit_\", \"\")\n",
    "            .str.replace(\"_\", \" \")\n",
    "            .str.title()\n",
    "        )\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"model\": \"Model\",\n",
    "                \"outfit\": \"Outfit\",\n",
    "                \"winner\": \"Winner\",\n",
    "                \"reason\": \"Reason\",\n",
    "                \"path\": \"Final GCS Path\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Display the table\n",
    "        print(\"\\n## ðŸ“‹ VTO Critique Summary Table\")\n",
    "        print(\"---\")\n",
    "        # Use to_markdown for a clean Colab table display\n",
    "        print(df.to_markdown(index=False, tablefmt=\"pipe\"))\n",
    "        print(\"---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to display CSV summary: {e}\")\n",
    "\n",
    "\n",
    "# ---------  Critique one model group ---------\n",
    "\n",
    "\n",
    "def process_critique_group(model_stamp, items_for_model):\n",
    "    model_path = next(\n",
    "        (\n",
    "            p\n",
    "            for p in list_top_level_pngs(BUCKET_NAME, MODELS_PREFIX)\n",
    "            if model_stamp.lower() in os.path.basename(p).lower()\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    if not model_path:\n",
    "        print(f\"No model image found for {model_stamp}\")\n",
    "        return []\n",
    "\n",
    "    out_rows = []\n",
    "\n",
    "    for outfit, cpaths in items_for_model:\n",
    "        outfit_path = f\"{OUTFITS_PREFIX}/{outfit}.png\"\n",
    "        if not bucket.blob(outfit_path).exists():\n",
    "            continue\n",
    "\n",
    "        winner, reason = judge(cpaths, model_path, outfit_path)\n",
    "\n",
    "        final_name = f\"{model_stamp}_TRYON4_{outfit}_FINAL.png\"\n",
    "        dst_rel = f\"{FINAL_PREFIX}/{final_name}\"\n",
    "\n",
    "        bucket.copy_blob(bucket.blob(cpaths[winner]), bucket, dst_rel)\n",
    "\n",
    "        out_rows.append(\n",
    "            {\n",
    "                \"model\": model_stamp,\n",
    "                \"outfit\": outfit,\n",
    "                \"winner\": winner,\n",
    "                \"reason\": reason,\n",
    "                \"path\": f\"gs://{BUCKET_NAME}/{dst_rel}\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return out_rows\n",
    "\n",
    "\n",
    "# --------- 5) Collect Candidates ---------\n",
    "groups = defaultdict(dict)\n",
    "for blob in storage_client.list_blobs(\n",
    "    BUCKET_NAME, prefix=f\"{VTO_OUTPUT_PREFIX}/\"\n",
    "):\n",
    "    if blob.name.lower().startswith(FINAL_PREFIX.lower() + \"/\"):\n",
    "        continue\n",
    "    m = CAND_RE.match(os.path.basename(blob.name))\n",
    "    if m:\n",
    "        groups[(m.group(\"modelStamp\"), m.group(\"outfit\"))][\n",
    "            f\"C{m.group('cid')}\"\n",
    "        ] = blob.name\n",
    "\n",
    "valid_groups = {k: v for k, v in groups.items() if len(v) == 4}\n",
    "\n",
    "by_model = defaultdict(list)\n",
    "for (ms, outfit), cpaths in valid_groups.items():\n",
    "    by_model[ms].append((outfit, cpaths))\n",
    "\n",
    "# --------- 6) Parallel Critique Execution ---------\n",
    "all_rows = []\n",
    "with ThreadPoolExecutor(max_workers=5) as ex:\n",
    "    futures = {\n",
    "        ex.submit(process_critique_group, m, pairs): m\n",
    "        for m, pairs in by_model.items()\n",
    "    }\n",
    "    for fut in as_completed(futures):\n",
    "        all_rows.extend(fut.result())\n",
    "\n",
    "# --------- 7) Save CSV Summary ---------\n",
    "if all_rows:\n",
    "    buf = io.StringIO()\n",
    "    writer = csv.DictWriter(\n",
    "        buf, fieldnames=[\"model\", \"outfit\", \"winner\", \"reason\", \"path\"]\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_rows)\n",
    "    bucket.blob(f\"{FINAL_PREFIX}/eval_summary.csv\").upload_from_string(\n",
    "        buf.getvalue(), content_type=\"text/csv\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[CSV] Saved summary â†’ gs://{BUCKET_NAME}/{FINAL_PREFIX}/eval_summary.csv\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No critique results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C57vaI8syqHU",
   "metadata": {
    "id": "C57vaI8syqHU"
   },
   "source": [
    "#Use Case 5  - Video Generation (Veo)\n",
    "\n",
    "Description: Generates runway walk videos using Veo based on the final tried-on images.\n",
    "- The process involves iterating through the final, selected VTO images from above step.\n",
    "\n",
    "- For each final image, call the Veo Video Generation Model.\n",
    "\n",
    "- The VTO image is used as the input image and a prompt (e.g., \"slowly walking on a white runway\") is provided to instruct the motion and environment.\n",
    "\n",
    "- The generated short video clips are uploaded to the final motion GCS prefix (dress/4tryon/final_motion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CboQHX_JywYl",
   "metadata": {
    "id": "CboQHX_JywYl"
   },
   "outputs": [],
   "source": [
    "VIDEO_PROMPT = (\n",
    "    \"Create a smooth video of the model walking a fashion runway wearing this outfit. \"\n",
    "    \"Show natural fabric motion to highlight flow, drape, and texture. \"\n",
    "    \"Preserve the modelâ€™s body type, skin tone, facial features, and the outfit exactly as in the reference image. \"\n",
    "    \"Use a clean seamless studio background. No added text, logos, or props.\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_motion(final_rel: str):\n",
    "    bucket = storage_client.bucket(BUCKET_NAME)\n",
    "    out_name = (\n",
    "        os.path.basename(final_rel)\n",
    "        .replace(\"_FINAL.png\", \"_MOTION.mp4\")\n",
    "        .replace(\"_FINAL.jpg\", \"_MOTION.mp4\")\n",
    "    )\n",
    "    out_rel = f\"{MOTION_OUTPUT_PREFIX}/{out_name}\"\n",
    "\n",
    "    if bucket.blob(out_rel).exists():\n",
    "        print(f\"[SKIP] Exists: {out_rel}\")\n",
    "        return\n",
    "\n",
    "    print(f\"[START] Generating video for {final_rel}...\")\n",
    "    try:\n",
    "        op = genai_client.models.generate_videos(\n",
    "            model=MODEL_VIDEO,\n",
    "            prompt=VIDEO_PROMPT,\n",
    "            image=GenAIImage(\n",
    "                gcs_uri=f\"gs://{BUCKET_NAME}/{final_rel}\", mime_type=\"image/png\"\n",
    "            ),\n",
    "            config=GenerateVideosConfig(\n",
    "                aspect_ratio=\"16:9\",\n",
    "                resolution=\"1080p\",\n",
    "                duration_seconds=8,\n",
    "                enhance_prompt=True,\n",
    "                generate_audio=False,\n",
    "                number_of_videos=1,\n",
    "            ),\n",
    "        )\n",
    "        while not op.done:\n",
    "            time.sleep(15)\n",
    "            op = genai_client.operations.get(op)\n",
    "\n",
    "        if op.result:\n",
    "            video_bytes = op.result.generated_videos[0].video.video_bytes\n",
    "            bucket.blob(out_rel).upload_from_string(\n",
    "                video_bytes, content_type=\"video/mp4\"\n",
    "            )\n",
    "            print(f\"[DONE] Saved: gs://{BUCKET_NAME}/{out_rel}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed video gen for {final_rel}: {e}\")\n",
    "\n",
    "\n",
    "# Execution\n",
    "print(\"[START] Veo Motion Generation\")\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "if not bucket.blob(f\"{MOTION_OUTPUT_PREFIX}/.keep\").exists():\n",
    "    bucket.blob(f\"{MOTION_OUTPUT_PREFIX}/.keep\").upload_from_string(\"\")\n",
    "\n",
    "# List finalized images\n",
    "final_blobs = list(\n",
    "    storage_client.list_blobs(BUCKET_NAME, prefix=FINAL_PREFIX + \"/\")\n",
    ")\n",
    "final_images = [\n",
    "    b.name for b in final_blobs if b.name.lower().endswith((\".png\", \".jpg\"))\n",
    "]\n",
    "\n",
    "# Run generation\n",
    "with ThreadPoolExecutor(max_workers=5) as ex:\n",
    "    futures = [ex.submit(generate_motion, f) for f in final_images]\n",
    "    for f in as_completed(futures):\n",
    "        f.result()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FReTKQdaeFis",
    "Nbdo05_pvczV",
    "FdXuyDT1vrkn",
    "jJBe_EcUv_iO",
    "JBcS4bb5wLjf",
    "QaVTCIINx8JZ",
    "C57vaI8syqHU"
   ],
   "name": "VTO_GenMedia_Workflow",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
