{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b56749a",
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright 2025 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "# cloud-solutions/ai-v0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583bd7c",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Imagen 4 Image Generation\n",
    "\n",
    "Use this notebook to generate reference images or upload your own assets before invoking the Imagen R2I model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bedf07a",
   "metadata": {
    "id": "G1KDmM_PBAXz"
   },
   "source": [
    "| Author |\n",
    "| --- |\n",
    "| [Isidro De Loera Jr](isidrodeloera@google.com) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b53a0",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The notebook designed to orchestrate Google Imagen reference-to-image (R2I) workflows within a standard Jupyter experience. It guides you through generating or uploading reference assets, reviewing previews, and invoking the R2I model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fcb1fa",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The notebook streamlines experimentation with Imagen 4 R2I by:\n",
    "- Generating optional content and style seed images.\n",
    "- Allowing user-supplied content/style uploads.\n",
    "- Enforcing preview steps so every asset is validated before it reaches the model.\n",
    "- Building the correct Google GenAI payloads for editing calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d48df0",
   "metadata": {},
   "source": [
    "## Scope\n",
    "This project covers the Jupyter-based workflow only. Backend services, web apps, or automation pipelines are out of scope. The notebook assumes you already have access to Google Cloud Vertex AI and the Imagen R2I models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49750619",
   "metadata": {},
   "source": [
    "## Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad1f3d",
   "metadata": {},
   "source": [
    "### Install Dependancies\n",
    "\n",
    "If you are using VS Code read more on how to [Manage Jupyter Kernels in VS Code](https://code.visualstudio.com/docs/datascience/jupyter-kernel-management). You will need to ensure you have executed `pip install ipykernel` on the local terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet google-genai \\\n",
    "                               ipywidgets \\ \n",
    "                               ipython \\ \n",
    "                               pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d8fa5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from io import BytesIO\n",
    "from typing import List, Literal, Optional, Tuple, Union\n",
    "\n",
    "import google.auth\n",
    "import ipywidgets as widgets\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import Image, Markdown, clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afaa48d",
   "metadata": {},
   "source": [
    "### Set Google Cloud project information\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd196a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEN_MODEL = os.environ.get(\"IMAGEN_MODEL\", \"imagen-4.0-generate-001\")\n",
    "R2I_MODEL = os.environ.get(\"R2I_MODEL\", \"imagen-4.0-ingredients-preview\")\n",
    "PROJECT_ID = os.environ.get(\n",
    "    \"GOOGLE_CLOUD_PROJECT\", \"consumer-genai-experiments\"\n",
    ")\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\")\n",
    "USE_PREPROD_ENDPOINT = False\n",
    "PREPROD_HTTP_ENDPOINT = \"https://us-central1-preprod-aiplatform.googleapis.com\"\n",
    "\n",
    "if PROJECT_ID in (None, \"\", \"<YOUR_GCP_PROJECT>\"):\n",
    "    raise ValueError(\n",
    "        \"Set GOOGLE_CLOUD_PROJECT or update PROJECT_ID with your GCP project ID.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc58d3",
   "metadata": {},
   "source": [
    "### Authenticate your notebook environment (Colab only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth  # pylint: disable=ungrouped-imports\n",
    "\n",
    "    auth.authenticate_user()\n",
    "    print(\"Authenticated as a user from colab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57f46b",
   "metadata": {},
   "source": [
    "### Authenticate your notebook environment (Manual)\n",
    "\n",
    "Log in to GCP from your on your local terminal.\n",
    "`gcloud auth application-default login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_gemini_with_gcloud(\n",
    "    project_id: str, location: str = \"us-central1\"\n",
    ") -> None:\n",
    "    \"\"\"Validates ADC, sets env vars for Vertex AI, and creates a global genai.Client().\"\"\"\n",
    "    global PROJECT_ID, LOCATION\n",
    "    resolved_project = project_id or \"\"\n",
    "    if not resolved_project:\n",
    "        raise ValueError(\n",
    "            \"Project ID is required. Provide one or set a default with `gcloud\"\n",
    "            \" config set project <PROJECT_ID>`.\"\n",
    "        )\n",
    "    resolved_location = (location or \"global\").strip()\n",
    "\n",
    "    # Configure environment so google-genai routes via Vertex AI\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"true\"\n",
    "    os.environ[\"GOOGLE_CLOUD_PROJECT\"] = resolved_project\n",
    "    os.environ[\"GOOGLE_CLOUD_LOCATION\"] = resolved_location\n",
    "\n",
    "    PROJECT_ID = resolved_project\n",
    "    LOCATION = resolved_location\n",
    "    print(f\"Gemini configured for project {PROJECT_ID} in location {LOCATION}.\")\n",
    "\n",
    "\n",
    "# --- Small UI to configure once ---\n",
    "project_input = widgets.Text(\n",
    "    value=PROJECT_ID,\n",
    "    description=\"Project ID:\",\n",
    "    placeholder=\"my-gcp-project\",\n",
    "    layout={\"width\": \"55%\"},\n",
    ")\n",
    "location_input = widgets.Text(\n",
    "    value=LOCATION or \"global\",\n",
    "    description=\"Location:\",\n",
    "    placeholder=\"global\",\n",
    "    layout={\"width\": \"55%\"},\n",
    ")\n",
    "configure_button = widgets.Button(\n",
    "    description=\"Configure Gemini\", button_style=\"success\", icon=\"check\"\n",
    ")\n",
    "config_output = widgets.Output()\n",
    "\n",
    "\n",
    "def on_configure_clicked(_):\n",
    "    with config_output:\n",
    "        config_output.clear_output()\n",
    "        try:\n",
    "            configure_gemini_with_gcloud(\n",
    "                project_input.value.strip(), location_input.value.strip()\n",
    "            )\n",
    "        except ValueError as exc:\n",
    "            print(f\"Configuration failed: {exc}\")\n",
    "\n",
    "\n",
    "configure_button.on_click(on_configure_clicked)\n",
    "display(project_input, location_input, configure_button, config_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0142fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default set-quota-project {os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"Project ID not found in os.environ\")}\n",
    "!gcloud config set project {os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"Project ID not found in os.environ\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4e339",
   "metadata": {},
   "source": [
    "### Get Credentials(Colab & Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86768343",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials, project = google.auth.default()\n",
    "print(\"ADC status:\", credentials is not None)\n",
    "print(\"ADC project:\", project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678cb2b9",
   "metadata": {},
   "source": [
    "## Create GCP Client\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_kwargs = dict(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "if USE_PREPROD_ENDPOINT:\n",
    "    client_kwargs[\"http_options\"] = {\"base_url\": PREPROD_HTTP_ENDPOINT}\n",
    "vertex_client = genai.Client(**client_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a0eb96",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONTENT_REFERENCES = 3\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ReferenceImage:\n",
    "    label: str\n",
    "    data: bytes\n",
    "    mime_type: str\n",
    "    source: Literal[\"generated\", \"uploaded\"]\n",
    "    reference_type: Literal[\"content\", \"style\"]\n",
    "\n",
    "\n",
    "content_references: List[ReferenceImage] = []\n",
    "style_reference: Optional[ReferenceImage] = None\n",
    "\n",
    "\n",
    "def clear_reference_state() -> None:\n",
    "    global content_references, style_reference\n",
    "    content_references = []\n",
    "    style_reference = None\n",
    "\n",
    "\n",
    "def extract_bytes_and_mime(\n",
    "    image_obj, fallback_mime: str = \"image/jpeg\"\n",
    ") -> Tuple[bytes, str]:\n",
    "    image = getattr(image_obj, \"image\", image_obj)\n",
    "    mime = (\n",
    "        getattr(image_obj, \"mime_type\", None)\n",
    "        or getattr(image, \"mime_type\", None)\n",
    "        or fallback_mime\n",
    "    )\n",
    "    image_bytes = getattr(image, \"image_bytes\", None) or getattr(\n",
    "        image_obj, \"image_bytes\", None\n",
    "    )\n",
    "    if image_bytes:\n",
    "        return bytes(image_bytes), mime\n",
    "    inline = getattr(image, \"inline_data\", None)\n",
    "    if inline:\n",
    "        data = getattr(inline, \"data\", None) or getattr(\n",
    "            inline, \"bytes_data\", None\n",
    "        )\n",
    "        inline_mime = getattr(inline, \"mime_type\", None) or mime\n",
    "        if data:\n",
    "            return bytes(data), inline_mime or mime\n",
    "    pil = getattr(image, \"_pil_image\", None)\n",
    "    if pil is not None:\n",
    "        buffer = BytesIO()\n",
    "        fmt = \"PNG\" if (mime or \"\").endswith(\"png\") else \"JPEG\"\n",
    "        pil.save(buffer, format=fmt)\n",
    "        return buffer.getvalue(), mime or f\"image/{fmt.lower()}\"\n",
    "    if isinstance(image_obj, (bytes, bytearray)):\n",
    "        return bytes(image_obj), mime\n",
    "    raise ValueError(\"Unable to extract bytes from provided image payload\")\n",
    "\n",
    "\n",
    "def preview_reference(ref: ReferenceImage) -> None:\n",
    "    display(\n",
    "        Markdown(\n",
    "            f\"**{ref.reference_type.title()} reference** - \"\n",
    "            f\"{ref.label} ({ref.source})\"\n",
    "        )\n",
    "    )\n",
    "    img_format = (\n",
    "        ref.mime_type.split(\"/\")[-1]\n",
    "        if ref.mime_type and \"/\" in ref.mime_type\n",
    "        else \"jpeg\"\n",
    "    )\n",
    "    display(Image(data=ref.data, format=img_format))\n",
    "\n",
    "\n",
    "def add_content_reference(ref: ReferenceImage) -> None:\n",
    "    if len(content_references) >= MAX_CONTENT_REFERENCES:\n",
    "        raise ValueError(\"Maximum content reference images reached.\")\n",
    "    content_references.append(ref)\n",
    "    preview_reference(ref)\n",
    "\n",
    "\n",
    "def set_style_reference(ref: ReferenceImage) -> None:\n",
    "    global style_reference\n",
    "    style_reference = ref\n",
    "    preview_reference(ref)\n",
    "\n",
    "\n",
    "def render_reference_summary() -> None:\n",
    "    if not content_references and not style_reference:\n",
    "        display(Markdown(\"No reference images selected yet.\"))\n",
    "        return\n",
    "    for ref in content_references:\n",
    "        preview_reference(ref)\n",
    "    if style_reference:\n",
    "        preview_reference(style_reference)\n",
    "\n",
    "\n",
    "def build_reference_payloads(\n",
    "    style_description: str,\n",
    ") -> List[Union[types.ContentReferenceImage, types.StyleReferenceImage]]:\n",
    "    if not content_references:\n",
    "        raise ValueError(\n",
    "            \"Add at least one content reference image before calling the R2I model.\"\n",
    "        )\n",
    "    references: List[\n",
    "        Union[types.ContentReferenceImage, types.StyleReferenceImage]\n",
    "    ] = []\n",
    "    for idx, ref in enumerate(content_references, 1):\n",
    "        references.append(\n",
    "            types.ContentReferenceImage(\n",
    "                reference_id=idx,\n",
    "                reference_image=types.Image(\n",
    "                    image_bytes=ref.data, mime_type=ref.mime_type\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    if style_reference:\n",
    "        description = style_description.strip() or \"style reference\"\n",
    "        references.append(\n",
    "            types.StyleReferenceImage(\n",
    "                reference_id=100,\n",
    "                reference_image=types.Image(\n",
    "                    image_bytes=style_reference.data,\n",
    "                    mime_type=style_reference.mime_type,\n",
    "                ),\n",
    "                config=types.StyleReferenceConfig(\n",
    "                    style_description=description\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    return references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e4ea5",
   "metadata": {},
   "source": [
    "### Generate or Upload Reference and Style Images\n",
    "\n",
    "#### Generate Reference Images (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9537d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input content generation prompts in the list below, add another prompt\n",
    "# to have 3 content references images\n",
    "content_generation_prompts = [\n",
    "    \"a close-up photo of a young woman\",\n",
    "    \"a close-up photo of a young man\",\n",
    "]\n",
    "style_generation_prompt = \"a painting in watercolor style\"\n",
    "style_description_default = \"watercolor style\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c52543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_references_from_prompts(\n",
    "    content_prompts,\n",
    "    style_prompt=None,\n",
    "    number_of_images: int = 1,\n",
    "    aspect_ratio: str = \"1:1\",\n",
    "    style_aspect_ratio: str = \"1:1\",\n",
    "    output_mime: str = \"image/jpeg\",\n",
    ") -> None:\n",
    "    for prompt in content_prompts:\n",
    "        if len(content_references) >= MAX_CONTENT_REFERENCES:\n",
    "            print(\n",
    "                \"Content reference limit reached; \"\n",
    "                \"skipping remaining prompts.\"\n",
    "            )\n",
    "            break\n",
    "        response = vertex_client.models.generate_images(\n",
    "            model=IMAGEN_MODEL,\n",
    "            prompt=prompt,\n",
    "            config=types.GenerateImagesConfig(\n",
    "                number_of_images=number_of_images,\n",
    "                aspect_ratio=aspect_ratio,\n",
    "                output_mime_type=output_mime,\n",
    "                include_rai_reason=True,\n",
    "            ),\n",
    "        )\n",
    "        images = getattr(response, \"images\", None)\n",
    "        if not images:\n",
    "            print(f\"No image returned for prompt: {prompt}\")\n",
    "            continue\n",
    "        image_obj = images[0]\n",
    "        data, mime = extract_bytes_and_mime(image_obj, output_mime)\n",
    "        try:\n",
    "            add_content_reference(\n",
    "                ReferenceImage(\n",
    "                    label=f\"Prompt: {prompt}\",\n",
    "                    data=data,\n",
    "                    mime_type=mime,\n",
    "                    source=\"generated\",\n",
    "                    reference_type=\"content\",\n",
    "                )\n",
    "            )\n",
    "        except ValueError as exc:\n",
    "            print(str(exc))\n",
    "            break\n",
    "    if style_prompt:\n",
    "        if style_reference:\n",
    "            print(\"Style reference already set; skipping generation.\")\n",
    "        else:\n",
    "            response = vertex_client.models.generate_images(\n",
    "                model=IMAGEN_MODEL,\n",
    "                prompt=style_prompt,\n",
    "                config=types.GenerateImagesConfig(\n",
    "                    number_of_images=1,\n",
    "                    aspect_ratio=style_aspect_ratio,\n",
    "                    output_mime_type=output_mime,\n",
    "                    include_rai_reason=True,\n",
    "                ),\n",
    "            )\n",
    "            images = getattr(response, \"images\", None)\n",
    "            if not images:\n",
    "                print(\"No style image returned.\")\n",
    "            else:\n",
    "                data, mime = extract_bytes_and_mime(images[0], output_mime)\n",
    "                set_style_reference(\n",
    "                    ReferenceImage(\n",
    "                        label=f\"Prompt: {style_prompt}\",\n",
    "                        data=data,\n",
    "                        mime_type=mime,\n",
    "                        source=\"generated\",\n",
    "                        reference_type=\"style\",\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_references_from_prompts(\n",
    "    content_generation_prompts,\n",
    "    style_prompt=style_generation_prompt,\n",
    "    aspect_ratio=\"1:1\",\n",
    "    style_aspect_ratio=\"16:9\",\n",
    "    output_mime=\"image/jpeg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05fe619",
   "metadata": {},
   "source": [
    "#### Upload Reference Images (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_description_default = \"water color painting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7024844",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_description_text = widgets.Text(\n",
    "    value=style_description_default,\n",
    "    description=\"Style desc\",\n",
    "    placeholder=\"Describe the style influence\",\n",
    ")\n",
    "content_upload = widgets.FileUpload(\n",
    "    accept=\"image/*\", multiple=True, description=\"Content uploads\"\n",
    ")\n",
    "style_upload = widgets.FileUpload(\n",
    "    accept=\"image/*\", multiple=False, description=\"Style upload\"\n",
    ")\n",
    "process_uploads_button = widgets.Button(\n",
    "    description=\"Add uploads\", button_style=\"primary\"\n",
    ")\n",
    "reset_button = widgets.Button(\n",
    "    description=\"Reset references\", button_style=\"warning\"\n",
    ")\n",
    "upload_feedback = widgets.Output()\n",
    "\n",
    "\n",
    "def _extract_files(upload_value):\n",
    "    if isinstance(upload_value, dict):\n",
    "        return list(upload_value.values())\n",
    "    return list(upload_value)\n",
    "\n",
    "\n",
    "def _file_info_to_reference(file_info, reference_type):\n",
    "    mime = file_info.get(\"type\") or \"image/jpeg\"\n",
    "    data = file_info.get(\"content\")\n",
    "    if data is None:\n",
    "        raise ValueError(\"Uploaded file payload is missing bytes.\")\n",
    "    if isinstance(data, memoryview):\n",
    "        data = data.tobytes()\n",
    "    elif isinstance(data, bytearray):\n",
    "        data = bytes(data)\n",
    "    elif not isinstance(data, bytes):\n",
    "        data = bytes(data)\n",
    "    return ReferenceImage(\n",
    "        label=f\"Upload: {file_info.get(\"name\", \"image\")}\",\n",
    "        data=data,\n",
    "        mime_type=mime,\n",
    "        source=\"uploaded\",\n",
    "        reference_type=reference_type,\n",
    "    )\n",
    "\n",
    "\n",
    "def process_uploads(_):\n",
    "    with upload_feedback:\n",
    "        clear_output()\n",
    "        style_files = _extract_files(style_upload.value)\n",
    "        if style_files:\n",
    "            if len(style_files) > 1:\n",
    "                print(\"Upload one style image at a time.\")\n",
    "            elif style_reference:\n",
    "                print(\"Style reference already set; reset to replace it.\")\n",
    "            else:\n",
    "                try:\n",
    "                    ref = _file_info_to_reference(style_files[0], \"style\")\n",
    "                    set_style_reference(ref)\n",
    "                except ValueError as exc:\n",
    "                    print(str(exc))\n",
    "            style_upload.value = ()\n",
    "            if hasattr(style_upload, \"_counter\"):\n",
    "                style_upload._counter = 0\n",
    "        content_files = _extract_files(content_upload.value)\n",
    "        if content_files:\n",
    "            for file_info in content_files:\n",
    "                if len(content_references) >= MAX_CONTENT_REFERENCES:\n",
    "                    print(\n",
    "                        \"Content reference limit reached; \"\n",
    "                        \"skipping remaining uploads.\"\n",
    "                    )\n",
    "                    break\n",
    "                try:\n",
    "                    ref = _file_info_to_reference(file_info, \"content\")\n",
    "                    add_content_reference(ref)\n",
    "                except ValueError as exc:\n",
    "                    print(str(exc))\n",
    "                    break\n",
    "            content_upload.value = ()\n",
    "            if hasattr(content_upload, \"_counter\"):\n",
    "                content_upload._counter = 0\n",
    "        if not style_files and not content_files:\n",
    "            print(\"No files to upload.\")\n",
    "\n",
    "\n",
    "def reset_references(_):\n",
    "    with upload_feedback:\n",
    "        clear_output()\n",
    "        clear_reference_state()\n",
    "        print(\"Cleared all references.\")\n",
    "\n",
    "\n",
    "process_uploads_button.on_click(process_uploads)\n",
    "reset_button.on_click(reset_references)\n",
    "\n",
    "display(\n",
    "    widgets.VBox(\n",
    "        [\n",
    "            widgets.HTML(\n",
    "                \"<b>Style description used for the style reference (if provided)</b>\"\n",
    "            ),\n",
    "            style_description_text,\n",
    "            widgets.HTML(\"<b>Upload reference images</b>\"),\n",
    "            widgets.HTML(\n",
    "                \"- Content: up to 3 images<br>- Style: at most 1 image\"\n",
    "            ),\n",
    "            widgets.HBox([content_upload, style_upload]),\n",
    "            widgets.HBox([process_uploads_button, reset_button]),\n",
    "            upload_feedback,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384fe5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_reference_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd950b",
   "metadata": {},
   "source": [
    "###  Invoke Imagen R2I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bdb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prompt below to combine images\n",
    "edit_prompt = (\n",
    "    \"a man, a woman, talking in a cafe in Lodon, looking at each other\"\n",
    ")\n",
    "edit_config = types.EditImageConfig(\n",
    "    aspect_ratio=\"9:16\",\n",
    "    number_of_images=1,\n",
    "    output_mime_type=\"image/jpeg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f824fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_description = (\n",
    "    style_description_text.value\n",
    "    if \"style_description_text\" in globals()\n",
    "    else style_description_default\n",
    ")\n",
    "reference_images = build_reference_payloads(style_description)\n",
    "response = vertex_client.models.edit_image(\n",
    "    model=R2I_MODEL,\n",
    "    prompt=edit_prompt,\n",
    "    reference_images=reference_images,\n",
    "    config=edit_config,\n",
    ")\n",
    "generated = getattr(response, \"generated_images\", None)\n",
    "if not generated:\n",
    "    raise ValueError(\"Model did not return any generated images.\")\n",
    "generated_bytes, generated_mime = extract_bytes_and_mime(\n",
    "    generated[0], \"image/jpeg\"\n",
    ")\n",
    "display(Markdown(\"**R2I output preview**\"))\n",
    "img_format = (\n",
    "    generated_mime.split(\"/\")[-1]\n",
    "    if generated_mime and \"/\" in generated_mime\n",
    "    else \"jpeg\"\n",
    ")\n",
    "display(Image(data=generated_bytes, format=img_format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbdbb52",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This repository is designed as a comprehensive resource to help you quickly locate and leverage GenAI solutions. Explore the assets, adapt the work as needed, and feel free to contribute improvements. Our structured, use-case-oriented approach ensures that useful solutions are easily accessible and ready to evolve.\n",
    "Happy innovating!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,nb.py"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
